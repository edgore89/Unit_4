{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords, gutenberg\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import ensemble\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth = gutenberg.raw('shakespeare-macbeth.txt')\n",
    "paradise = gutenberg.raw('milton-paradise.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split()[:5000])\n",
    "    return text\n",
    "\n",
    "macbeth = text_cleaner(macbeth)\n",
    "paradise = text_cleaner(paradise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse using SpaCy\n",
    "macbeth_doc = nlp(macbeth)\n",
    "paradise_doc = nlp(paradise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Actus, Primus, .)</td>\n",
       "      <td>Shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Scoena, Prima, .)</td>\n",
       "      <td>Shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Thunder, and, Lightning, .)</td>\n",
       "      <td>Shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Enter, three, Witches, .)</td>\n",
       "      <td>Shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, .)</td>\n",
       "      <td>Shakespeare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0            1\n",
       "0            (Actus, Primus, .)  Shakespeare\n",
       "1            (Scoena, Prima, .)  Shakespeare\n",
       "2  (Thunder, and, Lightning, .)  Shakespeare\n",
       "3    (Enter, three, Witches, .)  Shakespeare\n",
       "4                        (1, .)  Shakespeare"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group into sentences\n",
    "macbeth_sents = [[sent, 'Shakespeare'] for sent in macbeth_doc.sents]\n",
    "paradise_sents = [[sent, 'Milton'] for sent in paradise_doc.sents]\n",
    "\n",
    "sentences = pd.DataFrame(macbeth_sents + paradise_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actus Primus. Scoena Prima. Thunder and Lightning. Enter three Witches. 1. When shall we three meet againe? In Thunder, Lightning, or in Raine? 2. When the Hurley-burley's done, When the Battaile's lost, and wonne 3. That will be ere the set of Sunne 1. Where the place? 2. Vpon the Heath 3. There to meet with Macbeth 1. I come, Gray-Malkin All. Padock calls anon: faire is foule, and foule is faire\n",
      "\n",
      "Macbethlength: 6238\n",
      "\n",
      " Book I Of Man's first disobedience, and the fruit Of that forbidden tree whose mortal taste Brought death into the World, and all our woe, With loss of Eden, till one greater Man Restore us, and regain the blissful seat, Sing, Heavenly Muse, that, on the secret top Of Oreb, or of Sinai, didst inspire That shepherd who first taught the chosen seed In the beginning how the heavens and earth Rose out of Chaos: or, if Sion hill Delight thee more, and Siloa's\n",
      "\n",
      "Paradise length: 5938\n"
     ]
    }
   ],
   "source": [
    "#Look at excerpts from each \n",
    "print(macbeth_doc[:100])\n",
    "print('\\nMacbethlength:', len(macbeth_doc))\n",
    "\n",
    "print('\\n', paradise_doc[:100])\n",
    "print('\\nParadise length:', len(paradise_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(text):\n",
    "    \n",
    "    allwords = [token.lemma_\n",
    "               for token in text if not token.is_punct\n",
    "               and not token.is_stop]\n",
    "    return [item[0] for item in Counter(allwords).most_common(500)]\n",
    "\n",
    "macbeth_words = bag_of_words(macbeth_doc)\n",
    "paradise_words = bag_of_words(paradise_doc)\n",
    "common_words = set(macbeth_words + paradise_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bow data frame\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Build data frame\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentences in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentences\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bid</th>\n",
       "      <th>stay</th>\n",
       "      <th>guest</th>\n",
       "      <th>prepare</th>\n",
       "      <th>deepe</th>\n",
       "      <th>depth</th>\n",
       "      <th>move</th>\n",
       "      <th>treasons</th>\n",
       "      <th>stature</th>\n",
       "      <th>hearke</th>\n",
       "      <th>...</th>\n",
       "      <th>bow</th>\n",
       "      <th>cover</th>\n",
       "      <th>appear</th>\n",
       "      <th>wast</th>\n",
       "      <th>ruin</th>\n",
       "      <th>one</th>\n",
       "      <th>chamber</th>\n",
       "      <th>man</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Actus, Primus, .)</td>\n",
       "      <td>Shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Scoena, Prima, .)</td>\n",
       "      <td>Shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Thunder, and, Lightning, .)</td>\n",
       "      <td>Shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Enter, three, Witches, .)</td>\n",
       "      <td>Shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, .)</td>\n",
       "      <td>Shakespeare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 888 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  bid stay guest prepare deepe depth move treasons stature hearke  \\\n",
       "0   0    0     0       0     0     0    0        0       0      0   \n",
       "1   0    0     0       0     0     0    0        0       0      0   \n",
       "2   0    0     0       0     0     0    0        0       0      0   \n",
       "3   0    0     0       0     0     0    0        0       0      0   \n",
       "4   0    0     0       0     0     0    0        0       0      0   \n",
       "\n",
       "      ...      bow cover appear wast ruin one chamber man  \\\n",
       "0     ...        0     0      0    0    0   0       0   0   \n",
       "1     ...        0     0      0    0    0   0       0   0   \n",
       "2     ...        0     0      0    0    0   0       0   0   \n",
       "3     ...        0     0      0    0    0   0       0   0   \n",
       "4     ...        0     0      0    0    0   0       0   0   \n",
       "\n",
       "                  text_sentence  text_source  \n",
       "0            (Actus, Primus, .)  Shakespeare  \n",
       "1            (Scoena, Prima, .)  Shakespeare  \n",
       "2  (Thunder, and, Lightning, .)  Shakespeare  \n",
       "3    (Enter, three, Witches, .)  Shakespeare  \n",
       "4                        (1, .)  Shakespeare  \n",
       "\n",
       "[5 rows x 888 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bow features\n",
    "bow = bow_features(sentences, common_words)\n",
    "bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth = gutenberg.sents('shakespeare-macbeth.txt')\n",
    "paradise = gutenberg.sents('milton-paradise.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of text\n",
    "macbeth_list = [\" \".join(sent) for sent in macbeth]\n",
    "paradise_list =[\" \".join(sent) for sent in paradise]\n",
    "joined = macbeth_list + paradise_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, \n",
    "                             min_df=2, \n",
    "                             stop_words='english',   \n",
    "                             use_idf=True,\n",
    "                             norm=u'l2', \n",
    "                             smooth_idf=True \n",
    "                            )\n",
    "\n",
    "tfidf = vectorizer.fit_transform(joined).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the feature sets using cross validation\n",
    "\n",
    "X_bow = bow.drop(['text_sentence', 'text_source'],1)\n",
    "Y_bow = bow['text_source']\n",
    "\n",
    "X_tfidf = tfidf\n",
    "Y_tfidf = ['Shakespeare']*len(macbeth_list) +['Milton']*len(paradise_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW Logistic Regression Scores: [0.91111111 0.85925926 0.88148148 0.87407407 0.88059701]\n",
      "Average Score: 0.8813045881702598\n",
      "\n",
      "Tfidf Logistic Regression Scores: [0.91766268 0.9481383  0.96138482 0.91611185 0.9241012 ]\n",
      "Average Score: 0.933479769996517\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr_bow = lr.fit(X_bow, Y_bow)\n",
    "print('BOW Logistic Regression Scores:', cross_val_score(lr_bow, X_bow,Y_bow, cv =5))\n",
    "print('Average Score:', np.mean(cross_val_score(lr_bow, X_bow, Y_bow, cv=5)))\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr_tfidf = lr.fit(X_tfidf, Y_tfidf)\n",
    "print('\\nTfidf Logistic Regression Scores:', cross_val_score(lr_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Average Score:', np.mean(cross_val_score(lr_tfidf, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW Random Forest Scores: [0.86666667 0.87407407 0.85925926 0.82962963 0.88059701]\n",
      "Average Score: 0.8649861802100608\n",
      "\n",
      "Tfidf RFC Scores: [0.84196547 0.90292553 0.89480692 0.86018642 0.87616511]\n",
      "Average Score: 0.8717527962584694\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc_bow = rfc.fit(X_bow, Y_bow)\n",
    "print('BOW Random Forest Scores:', cross_val_score(rfc_bow, X_bow, Y_bow, cv =5))\n",
    "print('Average Score:', np.mean(cross_val_score(rfc_bow, X_bow, Y_bow, cv=5)))\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc_tfidf = rfc.fit(X_tfidf, Y_tfidf)\n",
    "print('\\nTfidf RFC Scores:', cross_val_score(rfc_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Average Score:', np.mean(cross_val_score(rfc_tfidf,X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW Gradient Boosting Scores [0.8962963  0.84444444 0.87407407 0.82962963 0.88059701]\n",
      "Average Score: 0.8561194029850746\n",
      "\n",
      "Tfidf Gradient Boosting Scores: [0.74103586 0.85638298 0.8828229  0.81491345 0.82556591]\n",
      "Average Score: 0.8241442197891157\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf_bow = clf.fit(X_bow, Y_bow)\n",
    "print('BOW Gradient Boosting Scores', cross_val_score(clf_bow, X_bow, Y_bow, cv =5))\n",
    "print('Average Score:', np.mean(cross_val_score(clf_bow, X_bow, Y_bow, cv =5)))\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf_tfidf = clf.fit(X_tfidf, Y_tfidf)\n",
    "print('\\nTfidf Gradient Boosting Scores:', cross_val_score(clf_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Average Score:', np.mean(cross_val_score(clf_tfidf,X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write up\n",
    "\n",
    "I got some pretty good scores from my models, but I would choose my Random forest model using TF-IDF since it has a score of 87% which is not too high or too low. I figured the accuracy scores would be high because Shakespeare and Milton have similar writing styles so I can assume they used many similar key words. \n",
    "\n",
    "I would try to improve the accuracy score for my TF-IDF gradient boosting model, but I am not sure sure what to modify in order to increase the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
